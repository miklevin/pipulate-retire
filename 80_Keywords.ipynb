{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb75517-3d31-4558-9c1b-bc513c82f30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import random\n",
    "import pandas as pd\n",
    "from sqlitedict import SqliteDict as sqldict\n",
    "from bs4 import BeautifulSoup as bsoup\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dd5409-8eee-4b48-ae15-3b44611288c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "responsedb = f\"{config.name}/responses.db\"\n",
    "\n",
    "# Get a count of the rows\n",
    "with sqldict(responsedb) as db:\n",
    "    for rows, url in enumerate(db):\n",
    "        ...\n",
    "\n",
    "# Show SEO fields for a random page from the crawl\n",
    "random_number = random.randint(0, rows)\n",
    "with sqldict(responsedb) as db:\n",
    "    for i, url in enumerate(db):\n",
    "        if i == random_number:\n",
    "            response = db[url]\n",
    "            soup = bsoup(response.text, \"html.parser\")\n",
    "            title = soup.title.string.strip()\n",
    "            description = soup.find('meta', attrs={'name': 'description'})['content']\n",
    "            canonical = soup.find('link', attrs={'rel': 'canonical'})['href']\n",
    "            headlines = soup.find_all([\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"])\n",
    "            headlines.sort(key=lambda x: int(x.name[1:]))\n",
    "            print(i, url)\n",
    "            print(f\"Canonical: {canonical}\")\n",
    "            print(f\"Status code: {response.status_code}\")\n",
    "            print(f\"Title: {title}\")\n",
    "            print(f\"Meta description: {description}\")\n",
    "            for i, headline in enumerate(headlines):\n",
    "                print(f\"{i+1} {headline.name}: {headline.text.strip()}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e6328a-55a8-40c7-a0ee-e4f1ba01bf95",
   "metadata": {},
   "source": [
    "# This Code is Markdown (not executable)\n",
    "\n",
    "The below code must be exeuted from a Terminal. It uses a special interactive mode of `readline` that only works properly from the command-line. The purpose of this is to extract a good list of keywords from your title tags.\n",
    "\n",
    "```python\n",
    "# file: pwgame.py\r\n",
    "import config\r\n",
    "import re\r\n",
    "import readline\r\n",
    "from pathlib import Path\r\n",
    "from collections import Counter\r\n",
    "from bs4 import BeautifulSoup as bsoup\r\n",
    "from sqlitedict import SqliteDict as sqldict\r\n",
    "\r\n",
    "responsedb = f\"{config.name}/responses.db\"\r\n",
    "keywordsdb = f\"{config.name}/keywords.db\"\r\n",
    "seenurlsdb = f\"{config.name}/seenurls.db\"\r\n",
    "\r\n",
    "def input_with_prefill(prefill):\r\n",
    "    readline.set_startup_hook(lambda: readline.insert_text(prefill))\r\n",
    "    try:\r\n",
    "        return input()\r\n",
    "    finally:\r\n",
    "        readline.set_startup_hook()\r\n",
    "\r\n",
    "pattern = \"( \\| | - | & )\"\r\n",
    "\r\n",
    "def kwclean(s):\r\n",
    "    s = s.replace(\" and \", \" \")\r\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\r\n",
    "    s = re.sub(pattern, \", \", s)\r\n",
    "    kwlist = s.split(\",\")\r\n",
    "    kwlist = [x.strip() for x in\n",
    "# Load already seen URLs into a set. kwlist]\r\n",
    "    return kwlist\r\n",
    "\r\n",
    "seen_urls = set()\r\n",
    "if Path(seenurlsdb).is_file():\r\n",
    "    with sqldict(seenurlsdb) as db:\r\n",
    "        for url in db\n",
    "# Load already seen keywords into a set.:\r\n",
    "            seen_urls.add(url)\r\n",
    "\r\n",
    "seen = set()\r\n",
    "if Path(keywordsdb).is_file():\r\n",
    "    with sqldict(keywordsdb) as db:\r\n",
    "        for kw i\n",
    "# Get a count of the number of title tags we will be looking at.n db:\r\n",
    "            seen.add(kw.lower())\r\n",
    "\r\n",
    "with sqldict(responsedb) as db:\r\n",
    "    for umpages, url in enumerate(dbf\"Processing {):\r\n",
    "     } pages.\"   ...\r\n",
    "\r\n",
    "countdown = numpages\r\n",
    "print(countdown)\r\n",
    "\r\n",
    "with sqldict(responsedb) as db:\r\n",
    "    for i, url in enumerate(db):\r\n",
    "        print(countdown-i)\r\n",
    "        if url not in seen_urls:\r\n",
    "           response = db[url]\r\n",
    "           soup = bsoup(response.text, \"html.parser\")\r\n",
    "           title = soup.title.string.strip()\r\n",
    "           title = \", \".join(kwclean(title))\r\n",
    "           before_kws = kwclean(title)\r\n",
    "           after_kws = []\r\n",
    "           counter = Counter()\r\n",
    "           for kw in before_kws:\r\n",
    "               kwlow = kw.lower()\r\n",
    "               if kwlow not in seen:\r\n",
    "                   after_kws.append(kw)\r\n",
    "               words = kw.split(\" \")\r\n",
    "               for word in words:\r\n",
    "                   counter[word] += 1\r\n",
    "           maxval = max(counter.values())\r\n",
    "           maxlabel = max(counter, key=counter.get)\r\n",
    "           mod_kws = []\r\n",
    "           for j, kw in enumerate(after_kws):\r\n",
    "               words = kw.split()\r\n",
    "               if j == 0:\r\n",
    "                   first = None\r\n",
    "                   if len(words) > 1:\r\n",
    "                       first = words[0]\r\n",
    "               if len(words) == 1:\r\n",
    "                   if maxval > 1:\r\n",
    "                       kw = f\"{maxlabel} {kw}\"\r\n",
    "                   elif first:\r\n",
    "                       kw = f\"{first} {kw}\"\r\n",
    "               chops = [\"More\"]\r\n",
    "               for chop in chops:\r\n",
    "                   if kw[:len(f\"{chop} \")].lower() == f\"{chop} \".lower():\r\n",
    "                       kw = kw[len(f\"{chop} \"):]\r\n",
    "               mod_kws.append(kw)\r\n",
    "           mod_kws = [x for x in mod_kws if x.lower() not in seen]\r\n",
    "           kw_str = \", \".join(mod_kws)\r\n",
    "           if not kw_str:\r\n",
    "               continue\r\n",
    "           collect = input_with_prefill(kw_str)\r\n",
    "           print(collect)\r\n",
    "           collect_list = collect.split(\",\")\r\n",
    "           collect_list = [x.strip() for x in collect_list]\r\n",
    "           with sqldict(keywordsdb) as db2:\r\n",
    "               for kw in collect_list:\r\n",
    "                   if kw and kw not in seen:\r\n",
    "                     db2[kw] = url\r\n",
    "                     seen.add(kw.lower())\r\n",
    "               db2.commit()\n",
    "```\r\n",
    "           with sqldict(seenurlsdb) as db2:\r\n",
    "             db2[url] = None\r\n",
    "             db2.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccb3636-be96-4a77-94b5-9c2b385db008",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywordsdb = f\"{config.name}/keywords.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d35258-67ca-4b15-ad91-77ace221ca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqldict(keywordsdb) as db:\n",
    "    for keyword in db:\n",
    "        url = db[keyword]\n",
    "        print(keyword, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df73724-7cbb-4a78-8137-e35497ee4af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqldict(keywordsdb) as db:\n",
    "    del db[\"G\"]\n",
    "    db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cf9dfe-6e40-47dd-9b88-e4c1e19de40d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
